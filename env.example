# OpenAI
OPENAI_API_KEY=sk-xxxxxxx
# OPENAI_BASE_URL はスキーム付きで指定してください（例: https://api.openai.com/v1）。
# スキームが無い場合は http:// が自動補完されます。
OPENAI_BASE_URL=
OPENAI_MODEL=gpt-5-mini
# OPENAI_TEMPERATURE は温度可変モデルのみ有効 (0.0～2.0)。gpt-5-mini など固定モデルでは無視されます。
OPENAI_TEMPERATURE=0.3
# gpt-5 系モデルを利用する際に応答の詳細度を制御する。low / medium / high から選択。
OPENAI_VERBOSITY=
# gpt-5 系モデル向けの推論強度。low / medium / high を指定し、空欄なら API 既定値。
OPENAI_REASONING_EFFORT=
# Responses API 呼び出しのタイムアウト秒数。通信断検知と再計画を迅速化する。
LLM_TIMEOUT_SECONDS=30

# WebSocket (Python -> Node)
WS_URL=ws://node-bot:8765
WS_HOST=0.0.0.0
WS_PORT=8765

# WebSocket (Node -> Python)
AGENT_WS_HOST=0.0.0.0
AGENT_WS_PORT=9000
AGENT_WS_URL=ws://python-agent:9000
DEFAULT_MOVE_TARGET=0,64,0
# キューの最大保持件数。0 にすると無制限。新しい指示を優先したい場合は小さめに設定する。
AGENT_QUEUE_MAX_SIZE=20
# チャット 1 件の処理タイムアウト秒数。長時間ブロックを避け、必要な場合のみ再試行する。
WORKER_TASK_TIMEOUT_SECONDS=300

# Control Mode (Mineflayer)
CONTROL_MODE=command
VPT_TICK_INTERVAL_MS=50
VPT_MAX_SEQUENCE_LENGTH=240

# Minecraft Server
MC_HOST=127.0.0.1
MC_PORT=25565
MC_VERSION=1.21.1

# AgentBridge HTTP Bridge
BRIDGE_URL=http://127.0.0.1:19071
BRIDGE_API_KEY=CHANGE_ME
BRIDGE_HTTP_TIMEOUT=3.0
BRIDGE_HTTP_RETRY=3

# Observability / OpenTelemetry
# OTLP コレクターのエンドポイント。未設定時は http://localhost:4318 を想定する。
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
# トレースのサンプリング率 (0.0～1.0)。1.0 で全件出力。
OTEL_TRACES_SAMPLER_RATIO=1.0

# Tunnel Mode Defaults
TUNNEL_TORCH_INTERVAL=8
TUNNEL_FUNCTIONAL_NEAR_RADIUS=4
TUNNEL_LIQUIDS_STOP=true
TUNNEL_WINDOW_LENGTH=8

# Bot Auth / Identity
BOT_USERNAME=HelperBot
AUTH_MODE=offline
